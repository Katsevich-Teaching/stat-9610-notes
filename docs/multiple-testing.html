<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>STAT 9610Lecture Notes - 5&nbsp; Multiple testing</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./glm-special-cases.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="custom.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./multiple-testing.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Multiple testing</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">STAT 9610<br>Lecture Notes</a> 
        <div class="sidebar-tools-main">
    <a href="./STAT-9610-br-Lecture-Notes.pdf" rel="" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Linear models: Estimation</span></span>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./linear-models-inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Linear models: Inference</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./linear-models-misspecification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Linear models: Misspecification</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./glm-general-theory.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Generalized linear models: General theory</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./glm-special-cases.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Generalized linear models: Special cases</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./multiple-testing.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Multiple testing</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-introduction-multiple-testing" id="toc-sec-introduction-multiple-testing" class="nav-link active" data-scroll-target="#sec-introduction-multiple-testing"><span class="header-section-number">5.1</span> Introduction to multiple testing</a>
  <ul class="collapse">
  <li><a href="#sec-multiplicity-problem" id="toc-sec-multiplicity-problem" class="nav-link" data-scroll-target="#sec-multiplicity-problem"><span class="header-section-number">5.1.1</span> The multiplicity problem</a></li>
  <li><a href="#sec-global-multiple-testing" id="toc-sec-global-multiple-testing" class="nav-link" data-scroll-target="#sec-global-multiple-testing"><span class="header-section-number">5.1.2</span> Global testing and multiple testing</a></li>
  <li><a href="#subsec-multiple-testing-goals" id="toc-subsec-multiple-testing-goals" class="nav-link" data-scroll-target="#subsec-multiple-testing-goals"><span class="header-section-number">5.1.3</span> Multiple testing goals</a></li>
  </ul></li>
  <li><a href="#sec-global-testing" id="toc-sec-global-testing" class="nav-link" data-scroll-target="#sec-global-testing"><span class="header-section-number">5.2</span> Global testing</a>
  <ul class="collapse">
  <li><a href="#sec-bonferroni-global-test" id="toc-sec-bonferroni-global-test" class="nav-link" data-scroll-target="#sec-bonferroni-global-test"><span class="header-section-number">5.2.1</span> Bonferroni global test (Bonferroni, 1936 and Dunn, 1961)</a></li>
  <li><a href="#sec-fisher-combination-test" id="toc-sec-fisher-combination-test" class="nav-link" data-scroll-target="#sec-fisher-combination-test"><span class="header-section-number">5.2.2</span> Fisher combination test (Fisher, 1925)</a></li>
  </ul></li>
  <li><a href="#sec-multiple-testing" id="toc-sec-multiple-testing" class="nav-link" data-scroll-target="#sec-multiple-testing"><span class="header-section-number">5.3</span> Multiple testing</a>
  <ul class="collapse">
  <li><a href="#sec-bonferroni-fwer" id="toc-sec-bonferroni-fwer" class="nav-link" data-scroll-target="#sec-bonferroni-fwer"><span class="header-section-number">5.3.1</span> The Bonferroni procedure for FWER control</a></li>
  <li><a href="#sec-bh-fdr" id="toc-sec-bh-fdr" class="nav-link" data-scroll-target="#sec-bh-fdr"><span class="header-section-number">5.3.2</span> The Benjamini-Hochberg procedure for FDR control</a></li>
  <li><a href="#sec-additional-topics" id="toc-sec-additional-topics" class="nav-link" data-scroll-target="#sec-additional-topics"><span class="header-section-number">5.3.3</span> Additional topics</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-multiple-testing" class="quarto-section-identifier"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Multiple testing</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="sec-introduction-multiple-testing" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="sec-introduction-multiple-testing"><span class="header-section-number">5.1</span> Introduction to multiple testing</h2>
<p>Consider the problem of assessing which variables in a GLM have nonzero coefficients. In the preceding chapters, we have described a variety of tests for obtaining <span class="math inline">\(p\)</span>-values for each coefficient. Given this set of <span class="math inline">\(p\)</span>-values (call them <span class="math inline">\(p_1\)</span>, , <span class="math inline">\(p_m\)</span>), we must determine which variables to deem significant. As it turns out, this task is a nontrivial one for several reasons, the first of which is the <em>multiplicity problem</em>.</p>
<section id="sec-multiplicity-problem" class="level3" data-number="5.1.1">
<h3 data-number="5.1.1" class="anchored" data-anchor-id="sec-multiplicity-problem"><span class="header-section-number">5.1.1</span> The multiplicity problem</h3>
<p>When R prints a regression summary, it adds stars to variables based on their <span class="math inline">\(p\)</span>-values. Variables with <span class="math inline">\(p\)</span>-values below 0.05 get one star, those with <span class="math inline">\(p\)</span>-values below 0.01 get two stars, and those with <span class="math inline">\(p\)</span>-values below 0.001 get three stars. A natural strategy for selecting significant variables is to choose those with one or more stars. However, the issue with this strategy is that even null variables (those with coefficients of zero) will sometimes have small <span class="math inline">\(p\)</span>-values by chance (<a href="#fig-spurious-correlation">Figure&nbsp;<span>5.1</span></a>). The more total variables we are testing, the more of them will have small <span class="math inline">\(p\)</span>-values by chance. This is the <em>multiplicity problem</em>.</p>
<div id="fig-spurious-correlation" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="figures/spurious-correlation.png" class="img-fluid figure-img" style="width:75.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;5.1: A spurious correlation resulting from data snooping.</figcaption>
</figure>
</div>
<p>To quantify this issue, consider the case when all <span class="math inline">\(m\)</span> variables under consideration are null. Then, the chance that any one of them has a <span class="math inline">\(p\)</span>-value below 0.05 is 0.05. So, the expected number of variables with one or more stars is <span class="math inline">\(0.05m\)</span>. For example, if we have 100 variables, then we expect to see 5 variables with stars on average, even though none of the variables are actually relevant to the response! The growth of the quantity <span class="math inline">\(0.05m\)</span> with <span class="math inline">\(m\)</span> confirms that the multiplicity problem grows more severe as the number of hypotheses tested increases.</p>
<p>Another way of thinking about the multiplicity problem is in the context of <em>selection bias</em>. The process of scanning across all variables and selecting those with small <span class="math inline">\(p\)</span>-values is a <em>selection event</em>. Once the selection event has occurred, one must consider the null distribution of a <span class="math inline">\(p\)</span>-value <em>conditionally on the fact that it was selected</em>. Since the selection event favors small <span class="math inline">\(p\)</span>-values, the null distribution of a <span class="math inline">\(p\)</span>-value conditional on selection is no longer uniform; it becomes skewed toward zero. Interpreting <span class="math inline">\(p\)</span>-values (and their accompanying stars) “at face value” is misleading because it ignores the crucial selection step. Other terms for this include “data snooping” and “p-hacking.”</p>
<p>The multiplicity problem is not limited to regression. In the next two sections, we develop some definitions to describe the multiplicity problem more formally and generally.</p>
</section>
<section id="sec-global-multiple-testing" class="level3" data-number="5.1.2">
<h3 data-number="5.1.2" class="anchored" data-anchor-id="sec-global-multiple-testing"><span class="header-section-number">5.1.2</span> Global testing and multiple testing</h3>
<p>Suppose we have <span class="math inline">\(m\)</span> null hypotheses <span class="math inline">\(H_{01}, \dots, H_{0m}\)</span>. Let $p_1, , <span class="math inline">\(p_m\)</span> be the corresponding <span class="math inline">\(p\)</span>-values.</p>
<div id="def-valid-p-value" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 5.1 </strong></span>A <span class="math inline">\(p\)</span>-value <span class="math inline">\(p_j\)</span> for a null hypothesis <span class="math inline">\(H_{0j}\)</span> is <em>valid</em> if <span id="eq-valid-p-value"><span class="math display">\[
\mathbb{P}_{H_{0j}}[p_j \leq t] \leq t \quad \text{for all } t \in [0, 1].
\tag{5.1}\]</span></span></p>
</div>
<p>This definition covers the uniform distribution, as well as distributions that are stochastically larger than uniform. Distributions of the latter kind are often obtained from resampling-based tests, such as permutation tests. In the remainder of this chapter, we will assume that all <span class="math inline">\(p\)</span>-values are valid.</p>
<p>Given a set of <span class="math inline">\(p\)</span>-values, there are several inferential goals potentially of interest. These can be subdivided first into <em>global testing</em> and <em>multiple testing</em>.</p>
<div id="def-global-testing" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 5.2 </strong></span>A <em>global testing procedure</em> is a test of the <em>global null hypothesis</em> <span class="math display">\[
H_0 \equiv \bigcap_{j = 1}^m H_{0j}.
\]</span> In other words, it is a function <span class="math inline">\(\phi: (p_1, \dots, p_m) \mapsto [0,1]\)</span>. A global test has level <span class="math inline">\(\alpha\)</span> if it controls the Type-I error at this level: <span id="eq-global-test-type-1-error"><span class="math display">\[
\mathbb{E}_{H_0}[\phi(p_1, \dots, p_m)] \leq \alpha.
\tag{5.2}\]</span></span></p>
</div>
<p>A global testing procedure determines whether <em>any</em> of the null hypotheses can be rejected. In regression modeling, a global test would be a test of the hypothesis <span class="math inline">\(H_0: \beta_1 = \cdots = \beta_m = 0\)</span>.</p>
<div id="def-multiple-testing" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 5.3 </strong></span>A <em>multiple testing procedure</em> is a mapping from the set of <span class="math inline">\(p\)</span>-values to a set of hypotheses to reject: <span class="math display">\[
\mathcal{M}: (p_1, \dots, p_m) \mapsto \hat{S} \subseteq \{1, \dots, m\}.
\]</span></p>
</div>
<p>A multiple testing procedure determines <em>which</em> of the null hypotheses can be rejected. In regression modeling, a multiple testing procedure would be a method for selecting which variables have nonzero coefficients, the problem we discussed in the beginning of this section.</p>
</section>
<section id="subsec-multiple-testing-goals" class="level3" data-number="5.1.3">
<h3 data-number="5.1.3" class="anchored" data-anchor-id="subsec-multiple-testing-goals"><span class="header-section-number">5.1.3</span> Multiple testing goals</h3>
<p>Let us define <span class="math display">\[
\mathcal{H}_0 \equiv \{j \in \{1, \dots, m\}: H_{0j} \text{ is true}\} \quad \text{and} \quad \mathcal{H}_1 \equiv \{j \in \{1, \dots, m\}: H_{0j} \text{ is false}\}.
\]</span></p>
<p>In other words, <span class="math inline">\(\mathcal{H}_0\)</span> is the set of indices of the true null hypotheses, and <span class="math inline">\(\mathcal{H}_1\)</span> is the set of indices of the false null hypotheses. There are two primary notions of Type-I error that multiple testing procedures seek to control: the <em>family-wise error rate</em> (FWER) and the <em>false discovery rate</em> (FDR).</p>
<section id="definitions-of-type-i-error-rate-and-power" class="level4" data-number="5.1.3.1">
<h4 data-number="5.1.3.1" class="anchored" data-anchor-id="definitions-of-type-i-error-rate-and-power"><span class="header-section-number">5.1.3.1</span> Definitions of Type-I error rate and power</h4>
<div id="def-fwer" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 5.4 </strong></span>The family-wise error rate (FWER) of a multiple testing procedure <span class="math inline">\(\mathcal{M}: (p_1, \dots, p_m) \mapsto \hat{S}\)</span> is the probability that it makes any false rejections: <span class="math display">\[
\text{FWER}(\mathcal{M}) \equiv \mathbb{P}[\hat{S} \cap \mathcal{H}_0 \neq \varnothing].
\]</span> A multiple testing procedure controls the FWER at level <span class="math inline">\(\alpha\)</span> if <span class="math display">\[
\text{FWER}(\mathcal{M}) \leq \alpha.
\]</span></p>
</div>
<div id="def-fdr" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 5.5 </strong></span>The false discovery proportion (FDP) of a rejection set <span class="math inline">\(\hat{S}\)</span> is the proportion of these rejections that are false: <span class="math display">\[
\text{FDP}(\hat{S}) \equiv \frac{|\hat{S} \cap \mathcal{H}_0|}{|\hat{S}|}, \quad \text{where} \quad \frac{0}{0} \equiv 0.
\]</span> The false discovery rate (FDR) of a multiple testing procedure <span class="math inline">\(\mathcal{M}: (p_1, \dots, p_m) \mapsto \hat{S}\)</span> is its expected false discovery proportion: <span id="eq-fdr-def"><span class="math display">\[
\text{FDR}(\mathcal{M}) \equiv \mathbb{E}[\text{FDP}(\hat{S})] = \mathbb{E}\left[\frac{|\hat{S} \cap \mathcal{H}_0|}{|\hat{S}|}\right].
\tag{5.3}\]</span></span> A multiple testing procedure controls the FDR at level <span class="math inline">\(q\)</span> if <span class="math display">\[
\text{FDR}(\mathcal{M}) \leq q.
\]</span></p>
</div>
<p>Regardless of what error rate a multiple testing procedure is intended to control, we would like it to have high <em>power</em>: <span class="math display">\[
\text{power}(\mathcal{M}) \equiv \mathbb{E}\left[\frac{|\hat{S} \cap \mathcal{H}_1|}{|\mathcal{H}_1|}\right].
\]</span></p>
</section>
<section id="relationship-between-the-fwer-and-fdr" class="level4" data-number="5.1.3.2">
<h4 data-number="5.1.3.2" class="anchored" data-anchor-id="relationship-between-the-fwer-and-fdr"><span class="header-section-number">5.1.3.2</span> Relationship between the FWER and FDR</h4>
<p>Note that the FWER is a probability, while the FDR is an expected proportion. This distinction is highlighted by using the different symbols <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(q\)</span> for the nominal FWER and FDR levels, respectively. The FWER is a more stringent error rate than the FDR, because it can only be low if <em>no</em> false discoveries are made most of the time; the FDR can be low if false discoveries are a small proportion of the total number of discoveries most of the time.</p>
<div id="prp-fwer-fdr" class="theorem proposition">
<p><span class="theorem-title"><strong>Proposition 5.1 </strong></span>For any multiple testing procedure <span class="math inline">\(\mathcal{M}\)</span>, we have <span class="math inline">\(\text{FDR}(\mathcal{M}) \leq \text{FWER}(\mathcal{M})\)</span>. Therefore, a multiple testing procedure controlling the FWER at level <span class="math inline">\(\alpha\)</span> also controls the FDR at level <span class="math inline">\(\alpha\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span><span class="math display">\[
\text{FDR} \equiv \mathbb{E}\left[\frac{|\hat{S} \cap \mathcal{H}_0|}{|\hat{S}|}\right] \leq \mathbb{E}\left[\mathbbm{1}(|\hat{S} \cap \mathcal{H}_0| &gt; 0)\right] \equiv \text{FWER}.
\]</span></p>
</div>
<p>The FWER was the error rate of choice in the 20th century, when limitations on data collection permitted only small handfuls of hypotheses to be tested. In the 21st century, the internet and other new technologies permitted much larger-scale collection of data, leading to much larger sets of hypotheses being tested (e.g., tens of thousands). In this context, the less stringent FDR rate became more popular. In many cases, an initial large-scale FDR-controlling procedure is viewed as an <em>exploratory analysis</em>, whose goal is to nominate a smaller number of hypotheses for confirmation with follow-up experiments. The purpose of controlling the FDR in this context is to limit resources wasted on following up false leads.</p>
</section>
</section>
</section>
<section id="sec-global-testing" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="sec-global-testing"><span class="header-section-number">5.2</span> Global testing</h2>
<p>Recall that a global test is a test of the intersection null hypothesis <span class="math inline">\(H_0 \equiv \cap_{j = 1}^m H_{0j}\)</span>. Let us first examine the naive global test, which rejects if any of the <span class="math inline">\(p\)</span>-values are below <span class="math inline">\(\alpha\)</span>: <span id="eq-naive-global-test"><span class="math display">\[
\phi_{\text{naive}}(p_1, \dots, p_m) = \mathbbm{1}\left(p_j \leq \alpha \text{ for some } j = 1, \dots, m\right).
\tag{5.4}\]</span></span></p>
<p>This test does not control the Type-I error. In fact, assuming the input <span class="math inline">\(p\)</span>-values are independent, we have <span class="math display">\[
\mathbb{E}_{H_0}[\phi_{\text{naive}}(p_1, \dots, p_m)] = 1-(1-\alpha)^m \rightarrow 1 \quad \text{as} \quad m \rightarrow \infty.
\]</span> This is a manifestation of the multiplicity problem discussed before. In this section, we will discuss two ways of adjusting for multiplicity in the context of global testing:</p>
<ul>
<li>Bonferroni test: Powerful against few strong signals.</li>
<li>Fisher combination test: Powerful against many weak signals.</li>
</ul>
<p>Each test is listed with the alternative against which it is powerful. Note that in the context of global testing and multiple testing, the alternative is a multivariate object. The main difference between the Bonferroni test and the Fisher combination test is how the signal (i.e., deviation from the null) is spread across the <span class="math inline">\(m\)</span> hypotheses being tested. If the signal is highly concentrated in a few non-null hypotheses, then the Bonferroni test is better. If the signal is spread out over many non-null hypotheses, then the Fisher combination test is better.</p>
<section id="sec-bonferroni-global-test" class="level3" data-number="5.2.1">
<h3 data-number="5.2.1" class="anchored" data-anchor-id="sec-bonferroni-global-test"><span class="header-section-number">5.2.1</span> Bonferroni global test (Bonferroni, 1936 and Dunn, 1961)</h3>
<section id="test-definition-and-validity" class="level4" data-number="5.2.1.1">
<h4 data-number="5.2.1.1" class="anchored" data-anchor-id="test-definition-and-validity"><span class="header-section-number">5.2.1.1</span> Test definition and validity</h4>
<p>The motivation for the Bonferroni global test is to find the strongest signal among the <span class="math inline">\(p\)</span>-values and reject the global null if this signal is strong enough. It makes sense that such a strategy would be powerful against sparse alternatives. We define the Bonferroni test via <span class="math display">\[
\phi(p_1, \dots, p_m) \equiv \mathbbm{1}\left(\min_{1 \leq j \leq m} p_j \leq \alpha/m\right).
\]</span></p>
<p>The Bonferroni global test rejects if any of the <span class="math inline">\(p\)</span>-values cross the <em>multiplicity-adjusted</em> or <em>Bonferroni-adjusted</em> significance threshold of <span class="math inline">\(\alpha/m\)</span>. This test can be viewed as a modified version of the naive test (<a href="#eq-naive-global-test"><span>5.4</span></a>), but with the significance threshold <span class="math inline">\(\alpha\)</span> adjusted downward to <span class="math inline">\(\alpha/m\)</span>. The more hypotheses we test, the more stringent the significance threshold must be.</p>
<div id="prp-bonferroni-fwer-control" class="theorem proposition">
<p><span class="theorem-title"><strong>Proposition 5.2 </strong></span>The Bonferroni test controls the FWER at level <span class="math inline">\(\alpha\)</span> for any joint dependence structure among the <span class="math inline">\(p\)</span>-values.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>We can verify the Type-I error control of the Bonferroni test via a union bound: <span class="math display">\[
\mathbb{P}_{H_0}\left[\min_{1 \leq j \leq m} p_j \leq \alpha/m\right] \leq \sum_{j = 1}^m \mathbb{P}_{H_{0j}}\left[p_j \leq \alpha/m\right] = m \cdot \alpha/m = \alpha.
\]</span></p>
</div>
</section>
<section id="the-impact-of-p-value-dependence" class="level4" data-number="5.2.1.2">
<h4 data-number="5.2.1.2" class="anchored" data-anchor-id="the-impact-of-p-value-dependence"><span class="header-section-number">5.2.1.2</span> The impact of <span class="math inline">\(p\)</span>-value dependence</h4>
<p>While the Bonferroni global test is valid for arbitrary <span class="math inline">\(p\)</span>-value dependence structures, the underlying union bound may be loose for certain dependence structures. In particular, the Bonferroni bound derived above is tightest for independent <span class="math inline">\(p\)</span>-values. Intuitively, the smallest <span class="math inline">\(p\)</span>-value has the highest chance of being small if each <span class="math inline">\(p\)</span>-value has its own independent source of randomness. Mathematically, let us compute the Type-I error of the Bonferroni global test under independence: <span class="math display">\[
\mathbb{P}_{H_0}\left[\min_{1 \leq j \leq m} p_j \leq \alpha/m\right] = 1 - (1-\alpha/m)^m \approx \alpha.
\]</span> Therefore, the Bonferroni test exhausts essentially its entire level under independence. On the other hand, under perfect dependence (i.e., <span class="math inline">\(p_1 = \cdots = p_m\)</span> almost surely), the Bonferroni test is quite conservative: <span class="math display">\[
\mathbb{P}_{H_0}\left[\min_{1 \leq j \leq m} p_j \leq \alpha/m\right] = \mathbb{P}_{H_{01}}\left[p_1 \leq \alpha/m\right] = \alpha/m.
\]</span> In this special case, the level is <span class="math inline">\(m\)</span> times lower than it should be, because no multiplicity adjustment is needed if the <span class="math inline">\(p\)</span>-values are perfectly dependent.</p>
</section>
</section>
<section id="sec-fisher-combination-test" class="level3" data-number="5.2.2">
<h3 data-number="5.2.2" class="anchored" data-anchor-id="sec-fisher-combination-test"><span class="header-section-number">5.2.2</span> Fisher combination test (Fisher, 1925)</h3>
<p>If, on the other hand, we expect the signal to be spread out over many non-null hypotheses, the valuable evidence against the alternative is missed if only the minimum <span class="math inline">\(p\)</span>-value is considered. In such circumstances, the Fisher combination test may be more powerful than the Bonferroni global test.</p>
<section id="test-definition-and-validity-1" class="level4" data-number="5.2.2.1">
<h4 data-number="5.2.2.1" class="anchored" data-anchor-id="test-definition-and-validity-1"><span class="header-section-number">5.2.2.1</span> Test definition and validity</h4>
<p>The Fisher combination test is based on the observation that <span class="math display">\[
\text{if } p \sim U[0,1], \quad \text{then} \quad -2\log p \sim \chi^2_2.
\]</span> Therefore, if <span class="math inline">\(p_1, \dots, p_m\)</span> are independent uniform random variables, then we have <span class="math display">\[
-2\sum_{j = 1}^m \log p_j \sim \chi^2_{2m}.
\]</span> This leads to the Fisher combination test: <span id="eq-fishers-formula"><span class="math display">\[
\phi(p_1, \dots, p_m) \equiv \mathbbm{1}\left(-2\sum_{j = 1}^m \log p_j \geq \chi^2_{2m}(1-\alpha)\right).
\tag{5.5}\]</span></span></p>
<div id="prp-fisher-type1-control" class="theorem proposition">
<p><span class="theorem-title"><strong>Proposition 5.3 </strong></span>The Fisher combination test controls Type-I error at level <span class="math inline">\(\alpha\)</span> (<a href="#eq-global-test-type-1-error"><span>5.2</span></a>) if the <span class="math inline">\(p\)</span>-values are independent.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Under the null, the <span class="math inline">\(p\)</span>-values are stochastically larger than uniform (<a href="#eq-fishers-formula"><span>5.5</span></a>). Therefore, <span class="math inline">\(-2\sum_{j = 1}^m \log p_j\)</span> is stochastically larger than <span class="math inline">\(\chi^2_{2m}\)</span>, from which the conclusion follows.</p>
</div>
</section>
<section id="discussion" class="level4" data-number="5.2.2.2">
<h4 data-number="5.2.2.2" class="anchored" data-anchor-id="discussion"><span class="header-section-number">5.2.2.2</span> Discussion</h4>
<p>The Fisher exact test has a similar flavor to another chi-squared test. Suppose <span class="math inline">\(X_j \sim N(\mu_j, 1)\)</span>, and we would like to test <span class="math inline">\(H_j: \mu_j = 0\)</span>. Under the global null, we have <span id="eq-chisquare-formula"><span class="math display">\[
\text{if } X_1, \dots, X_m \overset{\text{i.i.d.}}\sim N(0,1), \text{ then } \sum_{j = 1}^m X_j^2 \sim \chi^2_m.
\tag{5.6}\]</span></span> It turns out that the tests based on (<a href="#eq-fishers-formula"><span>5.5</span></a>) and (<a href="#eq-chisquare-formula"><span>5.6</span></a>) are quite similar. This helps us build intuition for what the Fisher combination test is doing: it’s averaging the strengths of the signal across hypotheses.</p>
<p>The independence assumption of the Fisher combination test makes it significantly less broadly applicable than the Bonferroni global test. However, one common application of the Fisher combination test is <em>meta-analysis</em>: the combination of information across multiple studies of the same hypothesis (or very related hypotheses). In this setting, the <span class="math inline">\(p\)</span>-values are independent across studies, and the Fisher combination test is a natural choice because the strength of the signal is roughly the same across studies since they are studying very related hypotheses.</p>
</section>
</section>
</section>
<section id="sec-multiple-testing" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="sec-multiple-testing"><span class="header-section-number">5.3</span> Multiple testing</h2>
<p>Here we present one method each for FWER and FDR control.</p>
<section id="sec-bonferroni-fwer" class="level3" data-number="5.3.1">
<h3 data-number="5.3.1" class="anchored" data-anchor-id="sec-bonferroni-fwer"><span class="header-section-number">5.3.1</span> The Bonferroni procedure for FWER control</h3>
<p>We discussed the Bonferroni test for the global null. This test can be extended to an FWER-controlling procedure:</p>
<p><span id="eq-bonferroni"><span class="math display">\[
\hat S \equiv \{j: p_j \leq \alpha/m\}
\tag{5.7}\]</span></span></p>
<div id="prp-bonferroni" class="theorem proposition">
<p><span class="theorem-title"><strong>Proposition 5.4 </strong></span>The Bonferroni procedure controls the FWER at level <span class="math inline">\(\alpha\)</span> for arbitrary <span class="math inline">\(p\)</span>-value dependence structures.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>We have</p>
<p><span class="math display">\[
\mathbb{P}[\hat S \cap \mathcal H_0 \neq \varnothing] = \mathbb{P}\left[\min_{j \in \mathcal H_0} p_j \leq \alpha/m\right] \leq \sum_{j \in \mathcal H_0} \mathbb{P}[p_j \leq \alpha/m] = \frac{|\mathcal H_0|}{m}\alpha \leq \alpha.
\]</span></p>
<p>This completes the proof.</p>
</div>
<p>Note that the FWER is actually controlled at the level <span class="math inline">\(\frac{|\mathcal H_0|}{m}\alpha \leq \alpha\)</span>, making the Bonferroni test conservative to the extent that <span class="math inline">\(|\mathcal H_0| &lt; m\)</span>. The null proportion <span class="math inline">\(\frac{|\mathcal H_0|}{m}\)</span> has such an effect on the performance of many multiple testing procedures. Not all global tests can be extended to FWER-controlling procedures in this way. For example, the Fisher combination test does not single out any of the hypotheses, as it only aggregates the <span class="math inline">\(p\)</span>-values. By contrast, the Bonferroni test searches for <span class="math inline">\(p\)</span>-values that are individually very small, allowing it to double as an FWER-controlling procedure.</p>
</section>
<section id="sec-bh-fdr" class="level3" data-number="5.3.2">
<h3 data-number="5.3.2" class="anchored" data-anchor-id="sec-bh-fdr"><span class="header-section-number">5.3.2</span> The Benjamini-Hochberg procedure for FDR control</h3>
<p>Designing procedures with FDR control, as well as verifying the latter property, is typically harder than for FWER control. It is harder to decouple the effects of the individual hypotheses, as the denominator <span class="math inline">\(|S|\)</span> in the FDR definition (<a href="#eq-fdr-def"><span>5.3</span></a>) couples them together. Both the FDR criterion and the most popular FDR-controlling procedure were proposed by Benjamini and Hochberg in 1995.</p>
<section id="procedure" class="level4" data-number="5.3.2.1">
<h4 data-number="5.3.2.1" class="anchored" data-anchor-id="procedure"><span class="header-section-number">5.3.2.1</span> Procedure</h4>
<p>To define the BH procedure, consider thresholding the <span class="math inline">\(p\)</span>-values at <span class="math inline">\(t \in [0,1]\)</span>. We would expect <span class="math inline">\(\mathbb{E}[|\{j: p_j \leq t\} \cap \mathcal H_0|] = |\mathcal H_0|t\)</span> false discoveries among <span class="math inline">\(\{j: p_j \leq t\}\)</span>. Since <span class="math inline">\(|\mathcal H_0|\)</span> is unknown, we can bound it from above by <span class="math inline">\(mt\)</span>. This leads to the FDP estimate:</p>
<p><span id="eq-fdp-estimate"><span class="math display">\[
\widehat{\text{FDP}}(t) \equiv \frac{mt}{|\{j: p_j \leq t\}|}
\tag{5.8}\]</span></span></p>
<p>The BH procedure is then defined via:</p>
<p><span id="eq-bh-procedure"><span class="math display">\[
\hat S \equiv \{j: p_j \leq \widehat t\}, \quad \text{where} \quad \widehat t = \max\{t \in [0,1]: \widehat{\text{FDP}}(t) \leq q\}
\tag{5.9}\]</span></span></p>
<p>In words, we choose the most liberal <span class="math inline">\(p\)</span>-value threshold for which the estimated FDP is below the nominal level <span class="math inline">\(q\)</span>. Note that the set over which the above maximum is taken is always nonempty because it at least contains 0: <span class="math inline">\(\widehat{\text{FDP}}(0) = \frac{0}{0} \equiv 0\)</span>.</p>
</section>
<section id="sec-fdr-control-independence" class="level4" data-number="5.3.2.2">
<h4 data-number="5.3.2.2" class="anchored" data-anchor-id="sec-fdr-control-independence"><span class="header-section-number">5.3.2.2</span> FDR control under independence</h4>
<p>Benjamini and Hochberg established that their procedure controls the FDR if the <span class="math inline">\(p\)</span>-values are independent. Here we present an alternative argument due to Storey, Taylor, and Siegmund (2004).</p>
<div id="prp-bh-fdr-control" class="theorem proposition">
<p><span class="theorem-title"><strong>Proposition 5.5 </strong></span>The BH procedure controls the FDR at level <span class="math inline">\(q\)</span> assuming that the <span class="math inline">\(p\)</span>-values are independent.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>We have</p>
<p><span class="math display">\[
\begin{split}
\text{FDR} &amp;= \mathbb{E}\left[\text{FDP}(\widehat t)\right] = \mathbb{E}\left[\frac{|\{j \in \mathcal H_0: p_j \leq \widehat t\}|}{|\{j: p_j \leq \widehat t\}|}\right] \\
&amp;= \mathbb{E}\left[\frac{|\{j \in \mathcal H_0: p_j \leq \widehat t\}|}{m \widehat t}\widehat{\text{FDP}}(\widehat t)\right] \leq q \cdot \mathbb{E}\left[\frac{|\{j \in \mathcal H_0: p_j \leq \widehat t\}|}{m \widehat t}\right].
\end{split}
\]</span></p>
<p>To prove that the last expectation is bounded above by 1, note that</p>
<p><span id="eq-martingale"><span class="math display">\[
M(t) \equiv \frac{|\{j \in \mathcal H_0: p_j \leq t\}|}{m t}
\tag{5.10}\]</span></span></p>
<p>is a backwards martingale with respect to the filtration</p>
<p><span id="eq-filtration"><span class="math display">\[
\mathcal F_t = \sigma(\{p_j: j \in \mathcal H_1\}, |\{j \in \mathcal H_0: p_j \leq t'\}| \text{ for } t' \geq t),
\tag{5.11}\]</span></span></p>
<p>with <span class="math inline">\(t\)</span> running backwards from 1 to 0. Indeed, for <span class="math inline">\(s &lt; t\)</span> we have</p>
<p><span class="math display">\[
\mathbb{E}[M(s)|\mathcal F_t] = \mathbb{E}\left[\left.\frac{|\{j \in \mathcal H_0: p_j \leq s\}|}{m s} \right| \mathcal F_t\right] = \frac{\frac{s}{t}|\{j \in \mathcal H_0: p_j \leq t\}|}{m s} = \frac{|\{j \in \mathcal H_0: p_j \leq t\}|}{m t} = M(t).
\]</span></p>
<p>The threshold <span class="math inline">\(\widehat t\)</span> is a stopping time with respect to this filtration, so by the optional stopping theorem, we have</p>
<p><span class="math display">\[
\mathbb{E}\left[\frac{|\{j \in \mathcal H_0: p_j \leq \widehat t\}|}{m \widehat t}\right] = \mathbb{E}[M(\widehat t)] \leq \mathbb{E}[M(1)] = \frac{|\mathcal H_0|}{m} \leq 1.
\]</span></p>
<p>This completes the proof.</p>
</div>
</section>
<section id="sec-fdr-control-dependence" class="level4" data-number="5.3.2.3">
<h4 data-number="5.3.2.3" class="anchored" data-anchor-id="sec-fdr-control-dependence"><span class="header-section-number">5.3.2.3</span> FDR control under dependence</h4>
<p>Under dependence, the BH procedure’s FDR can be bounded by a multiple of the nominal FDR level.</p>
<div id="prp-bh-dependence" class="theorem proposition">
<p><span class="theorem-title"><strong>Proposition 5.6 </strong></span>The BH procedure controls the FDR at level <span class="math inline">\(q(1 + \frac{1}{2} + \cdots + \frac{1}{m})\)</span> regardless of the <span class="math inline">\(p\)</span>-value dependency structure.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>We have</p>
<p><span class="math display">\[
\begin{split}
\text{FDP}(\hat S) &amp;= \sum_{k = 1}^m \frac{|\hat S \cap \mathcal H_0|}{k}\mathbbm{1}(|\hat S| = k) \\
&amp;= \sum_{k = 1}^m \sum_{j \in \mathcal H_0} \frac{1}{k}\mathbbm{1}(j \in \hat S, |\hat S| = k) \\
&amp;= \sum_{k = 1}^m \sum_{j \in \mathcal H_0} \frac{1}{k}\mathbbm{1}\left(p_j \leq \frac{qk}{m}, |\hat S| = k\right) \\
&amp;\leq \sum_{j \in \mathcal H_0} \sum_{l = 1}^m \frac{1}{l} \mathbbm{1}\left(p_j \in \left[\frac{q(l-1)}{m}, \frac{ql}{m}\right]\right).
\end{split}
\]</span></p>
<p>It follows that</p>
<p><span class="math display">\[
\text{FDR} = \mathbb{E}[\text{FDP}(\hat S)] \leq \frac{|\mathcal H_0|}{m}q\left(1 + \frac{1}{2} + \cdots + \frac{1}{m}\right).
\]</span></p>
<p>This completes the proof.</p>
</div>
</section>
</section>
<section id="sec-additional-topics" class="level3" data-number="5.3.3">
<h3 data-number="5.3.3" class="anchored" data-anchor-id="sec-additional-topics"><span class="header-section-number">5.3.3</span> Additional topics</h3>
<section id="sec-weighted-multiple-testing" class="level4" data-number="5.3.3.1">
<h4 data-number="5.3.3.1" class="anchored" data-anchor-id="sec-weighted-multiple-testing"><span class="header-section-number">5.3.3.1</span> Weighted multiple testing procedures</h4>
<p>Sometimes, we may have more prior evidence against certain null hypotheses than others, which we wish to incorporate in the global testing or multiple testing procedure to boost power. A common approach to doing so is to <em>weight</em> the <span class="math inline">\(p\)</span>-values. Letting <span class="math inline">\(w_1, \dots, w_m\)</span> be <span class="math inline">\(p\)</span>-value weights averaging to 1, define <em>weighted <span class="math inline">\(p\)</span>-values</em> <span class="math inline">\(\tilde{p}_j\)</span> via:</p>
<p><span id="eq-weighted-p-values"><span class="math display">\[
\tilde{p}_j \equiv \frac{p_j}{w_j}
\tag{5.12}\]</span></span></p>
<p>Note that <span class="math inline">\(p\)</span>-values corresponding to hypotheses with large (small) weights will be made more (less) significant. We can then attempt to apply the above global testing and multiple testing procedures on the weighted <span class="math inline">\(p\)</span>-values <span class="math inline">\(\tilde{p}_j\)</span> rather than the original <span class="math inline">\(p\)</span>-values <span class="math inline">\(p_j\)</span>. As it turns out, in many cases these weighted procedures retain the Type-I error guarantees of their unweighted counterparts.</p>
<div id="prp-weighted-bonferroni" class="theorem proposition">
<p><span class="theorem-title"><strong>Proposition 5.7 </strong></span>The weighted variants of the Bonferroni global test, the Bonferroni FWER procedure, and the BH FDR procedure all control their respective Type-I error rates under the same conditions as their unweighted counterparts (arbitrary dependence for the Bonferroni procedures and independence for BH).</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Here, we prove the statement just for the Bonferroni global test; the remaining proofs are left as exercises. The weighted Bonferroni global test is as follows:</p>
<p><span class="math display">\[
\phi(p_1, \dots, p_m) \equiv \mathbbm{1}\left(\min_{1 \leq j \leq m} \frac{p_j}{w_j} \leq \frac{\alpha}{m}\right).
\]</span></p>
<p>It follows that</p>
<p><span class="math display">\[
\mathbb{E}_{H_0}[\phi(p_1, \dots, p_m)] \leq \sum_{j = 1}^m \frac{\alpha}{m} w_j = \alpha.
\]</span></p>
<p>The last equality follows from the fact that the weights <span class="math inline">\(w_j\)</span> average to 1 by assumption.</p>
<p>This completes the proof.</p>
</div>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./glm-special-cases.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Generalized linear models: Special cases</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->



</body></html>