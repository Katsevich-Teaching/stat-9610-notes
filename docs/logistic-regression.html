<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>STAT 9610 Lecture Notes - 24&nbsp; Logistic regression</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./poisson-regression.html" rel="next">
<link href="./glm-special-cases.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./glm-special-cases.html">Generalized linear models: Special cases</a></li><li class="breadcrumb-item"><a href="./logistic-regression.html"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Logistic regression</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">STAT 9610 Lecture Notes</a> 
        <div class="sidebar-tools-main">
    <a href="./STAT-9610-Lecture-Notes.pdf" rel="" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./linear-models-estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Linear models: Estimation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./interpreting-linear-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Interpreting linear models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./least-squares-estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Least squares estimation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./anova.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Analysis of variance</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./collinearity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Collinearity and adjustment</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./r-demo-part-1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">R demo</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./linear-models-inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Linear models: Inference</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./building-blocks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Building blocks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hypothesis-testing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Hypothesis testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./power.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Power</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./confidence-intervals.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Confidence intervals</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./practical-considerations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Practical considerations</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./r-demo-part-2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">R demo</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./linear-models-misspecification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Linear models: Misspecification</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./misspecification-overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Overview</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./asymptotic-methods.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Asymptotic methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bootstrap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">The bootstrap</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./permutation-test.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">The permutation test</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./robust-estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Robust estimation and inference</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./r-demo-part-3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">R demo</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./glm-general-theory.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Generalized linear models: General theory</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./exponential-dispersion-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Exponential dispersion model (EDM) distributions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./generalized-linear-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">GLM definition</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./parameter-estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Parameter estimation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./glm-inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Inference in GLMs</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./r-demo-part-4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">R demo</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./glm-special-cases.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Generalized linear models: Special cases</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./logistic-regression.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Logistic regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./poisson-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Poisson regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./negative-binomial-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Negative binomial regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./r-demo-part-5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">R demo</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./multiple-testing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Multiple testing</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./multiple-testing-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./global-testing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Global testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./multiple-testing-chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Multiple testing</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-logistic-model" id="toc-sec-logistic-model" class="nav-link active" data-scroll-target="#sec-logistic-model"><span class="header-section-number">24.1</span> Model definition and interpretation</a>
  <ul class="collapse">
  <li><a href="#model-definition." id="toc-model-definition." class="nav-link" data-scroll-target="#model-definition."><span class="header-section-number">24.1.1</span> Model definition.</a></li>
  <li><a href="#generative-model-equivalent." id="toc-generative-model-equivalent." class="nav-link" data-scroll-target="#generative-model-equivalent."><span class="header-section-number">24.1.2</span> Generative model equivalent.</a></li>
  <li><a href="#sec-2x2-contingency" id="toc-sec-2x2-contingency" class="nav-link" data-scroll-target="#sec-2x2-contingency"><span class="header-section-number">24.1.3</span> Special case: <span class="math inline">\(2 \times 2\)</span> contingency table.</a></li>
  </ul></li>
  <li><a href="#sec-logistic-case-control" id="toc-sec-logistic-case-control" class="nav-link" data-scroll-target="#sec-logistic-case-control"><span class="header-section-number">24.2</span> Logistic regression with case-control studies</a></li>
  <li><a href="#sec-estimation-inference" id="toc-sec-estimation-inference" class="nav-link" data-scroll-target="#sec-estimation-inference"><span class="header-section-number">24.3</span> Estimation and inference</a>
  <ul class="collapse">
  <li><a href="#sec-score-fisher" id="toc-sec-score-fisher" class="nav-link" data-scroll-target="#sec-score-fisher"><span class="header-section-number">24.3.1</span> Score and Fisher information</a></li>
  <li><a href="#sec-wald-inference" id="toc-sec-wald-inference" class="nav-link" data-scroll-target="#sec-wald-inference"><span class="header-section-number">24.3.2</span> Wald inference</a></li>
  <li><a href="#sec-2x2-contingency-table" id="toc-sec-2x2-contingency-table" class="nav-link" data-scroll-target="#sec-2x2-contingency-table"><span class="header-section-number">24.3.3</span> Example: <span class="math inline">\(2 \times 2\)</span> contingency table.</a></li>
  <li><a href="#sec-hauck-donner-effect" id="toc-sec-hauck-donner-effect" class="nav-link" data-scroll-target="#sec-hauck-donner-effect"><span class="header-section-number">24.3.4</span> Hauck-Donner effect.</a></li>
  <li><a href="#sec-likelihood-ratio-inference" id="toc-sec-likelihood-ratio-inference" class="nav-link" data-scroll-target="#sec-likelihood-ratio-inference"><span class="header-section-number">24.3.5</span> Likelihood ratio inference</a></li>
  <li><a href="#sec-comparing-deviances" id="toc-sec-comparing-deviances" class="nav-link" data-scroll-target="#sec-comparing-deviances"><span class="header-section-number">24.3.6</span> Comparing the deviances of grouped and ungrouped logistic regression models.</a></li>
  </ul></li>
  <li><a href="#sec-goodness-of-fit" id="toc-sec-goodness-of-fit" class="nav-link" data-scroll-target="#sec-goodness-of-fit"><span class="header-section-number">24.4</span> Goodness of fit testing</a></li>
  <li><a href="#sec-example-2x2-table" id="toc-sec-example-2x2-table" class="nav-link" data-scroll-target="#sec-example-2x2-table"><span class="header-section-number">24.5</span> Example: <span class="math inline">\(2 \times 2\)</span> table</a></li>
  <li><a href="#sec-score-based-inference" id="toc-sec-score-based-inference" class="nav-link" data-scroll-target="#sec-score-based-inference"><span class="header-section-number">24.6</span> Score-based inference</a></li>
  <li><a href="#sec-fisher-exact-test" id="toc-sec-fisher-exact-test" class="nav-link" data-scroll-target="#sec-fisher-exact-test"><span class="header-section-number">24.7</span> Fisher’s exact test</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-logistic-regression" class="quarto-section-identifier"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Logistic regression</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="sec-logistic-model" class="level2" data-number="24.1">
<h2 data-number="24.1" class="anchored" data-anchor-id="sec-logistic-model"><span class="header-section-number">24.1</span> Model definition and interpretation</h2>
<section id="model-definition." class="level3" data-number="24.1.1">
<h3 data-number="24.1.1" class="anchored" data-anchor-id="model-definition."><span class="header-section-number">24.1.1</span> Model definition.</h3>
<p>Recall from Chapter 4 that the logistic regression model is <span class="math display">\[
m_i y_i \overset{\text{ind}} \sim \text{Bin}(m_i, \pi_i); \quad \text{logit}(\pi_i) = \log\frac{\pi_i}{1-\pi_i} = \boldsymbol{x}^T_{i*}\boldsymbol{\beta}.
\]</span> Here we use the canonical logit link function, although other link functions are possible. We also set the offsets to 0. The interpretation of the parameter <span class="math inline">\(\beta_j\)</span> is that a unit increase in <span class="math inline">\(x_j\)</span>—other predictors held constant—is associated with an (additive) increase of <span class="math inline">\(\beta_j\)</span> on the log-odds scale or a multiplicative increase of <span class="math inline">\(e^{\beta_j}\)</span> on the odds scale. Note that logistic regression data come in two formats: <em>ungrouped</em> and <em>grouped</em>. For ungrouped data, we have <span class="math inline">\(m_1 = \dots = m_n = 1\)</span>, so <span class="math inline">\(y_i \in \{0,1\}\)</span> are Bernoulli random variables. For grouped data, we can have several independent Bernoulli observations per predictor <span class="math inline">\(\boldsymbol{x}_{i*}\)</span>, which give rise to binomial proportions <span class="math inline">\(y_i \in [0,1]\)</span>. This happens most often when all the predictors are discrete. You can always convert grouped data into ungrouped data, but not necessarily vice versa. We’ll discuss below that the grouped and ungrouped formulations of logistic regression have the same MLE and standard errors but different deviances.</p>
</section>
<section id="generative-model-equivalent." class="level3" data-number="24.1.2">
<h3 data-number="24.1.2" class="anchored" data-anchor-id="generative-model-equivalent."><span class="header-section-number">24.1.2</span> Generative model equivalent.</h3>
<p>Consider the following generative model for <span class="math inline">\((\boldsymbol{x}, y) \in \mathbb{R}^{p-1} \times \{0,1\}\)</span>: <span class="math display">\[
y \sim \text{Ber}(\pi); \quad \boldsymbol{x}|y \sim \begin{cases} N(\boldsymbol{\mu}_0, \boldsymbol{V}) \quad \text{if } y = 0 \\ N(\boldsymbol{\mu}_1, \boldsymbol{V}) \quad \text{if } y = 1 \end{cases}.
\]</span> Then, we can derive that <span class="math inline">\(y|\boldsymbol{x}\)</span> follows a logistic regression model (called a <em>discriminative</em> model because it conditions on <span class="math inline">\(\boldsymbol{x}\)</span>). Indeed, <span class="math display">\[
\begin{aligned}
\text{logit}(p(y = 1|\boldsymbol{x})) &amp;= \log\frac{p(y = 1)p(\boldsymbol{x}|y = 1)}{p(y = 0)p(\boldsymbol{x}|y = 0)} \\
&amp;= \log\frac{\pi \exp\left(-\frac12(\boldsymbol{x} - \boldsymbol{\mu}_1)^T \boldsymbol{V}^{-1}(\boldsymbol{x} - \boldsymbol{\mu}_1)\right)}{(1-\pi) \exp\left(-\frac12(\boldsymbol{x} - \boldsymbol{\mu}_0)^T \boldsymbol{V}^{-1}(\boldsymbol{x} - \boldsymbol{\mu}_0)\right)} \\
&amp;= \beta_0 + \boldsymbol{x}^T \boldsymbol{V}^{-1}(\boldsymbol{\mu}_1 - \boldsymbol{\mu}_0) \\
&amp;\equiv \beta_0 + \boldsymbol{x}^T \boldsymbol{\beta}_{-0}.
\end{aligned}
\]</span> This is another natural route to motivating the logistic regression model.</p>
</section>
<section id="sec-2x2-contingency" class="level3" data-number="24.1.3">
<h3 data-number="24.1.3" class="anchored" data-anchor-id="sec-2x2-contingency"><span class="header-section-number">24.1.3</span> Special case: <span class="math inline">\(2 \times 2\)</span> contingency table.</h3>
<p>Suppose that <span class="math inline">\(x \in \{0,1\}\)</span>, and consider the logistic regression model <span class="math inline">\(\text{logit}(\pi_i) = \beta_0 + \beta_1 x_i\)</span>. For example, suppose that <span class="math inline">\(x \in \{0,1\}\)</span> encodes treatment (1) and control (0) in a clinical trial, and <span class="math inline">\(y_i \in \{0,1\}\)</span> encodes success (1) and failure (0). We make <span class="math inline">\(n\)</span> observations of <span class="math inline">\((x_i, y_i)\)</span> in this ungrouped setup. The parameter <span class="math inline">\(e^{\beta_1}\)</span> can be interpreted as the <em>odds ratio</em>: <span class="math display">\[
e^{\beta_1} = \frac{\mathbb{P}[y = 1|x=1]/\mathbb{P}[y = 0|x=1]}{\mathbb{P}[y = 1|x=0]/\mathbb{P}[y = 0|x=0]}.
\]</span> This parameter is the multiple by which the odds of success increase when going from control to treatment. We can summarize such data via the <span class="math inline">\(2 \times 2\)</span> <em>contingency table</em> (<a href="#tbl-2-by-2-table">Table&nbsp;<span>24.1</span></a>). A grouped version of this data would be <span class="math inline">\(\{(x_1, y_1) = (0, 7/24), (x_2, y_2) = (1, 9/21)\}\)</span>. The null hypothesis <span class="math inline">\(H_0: \beta_1 = 0 \Longleftrightarrow H_0: e^{\beta_1} = 1\)</span> states that the success probability in both rows of the table is the same.</p>
<div id="tbl-2-by-2-table" class="anchored">
<table class="table">
<caption>Table&nbsp;24.1: An example of a <span class="math inline">\(2 \times 2\)</span> contingency table.</caption>
<thead>
<tr class="header">
<th></th>
<th>Success</th>
<th>Failure</th>
<th>Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Treatment</td>
<td>9</td>
<td>12</td>
<td>21</td>
</tr>
<tr class="even">
<td>Control</td>
<td>7</td>
<td>17</td>
<td>24</td>
</tr>
<tr class="odd">
<td>Total</td>
<td>16</td>
<td>29</td>
<td>45</td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
<section id="sec-logistic-case-control" class="level2" data-number="24.2">
<h2 data-number="24.2" class="anchored" data-anchor-id="sec-logistic-case-control"><span class="header-section-number">24.2</span> Logistic regression with case-control studies</h2>
<p>In a prospective study (e.g.&nbsp;a clinical trial), we assign treatment or control (i.e., <span class="math inline">\(x\)</span>) to individuals, and then observe a binary outcome (i.e., <span class="math inline">\(y\)</span>). Sometimes, the outcome <span class="math inline">\(y\)</span> takes a long time to measure or has a highly imbalanced distribution in the population (e.g., the development of lung cancer). In this case, an appealing study design is the <em>retrospective study</em>, where individuals are sampled based on their <em>response values</em> (e.g., presence of lung cancer) rather than their treatment/exposure status (e.g., smoking). It turns out that a logistic regression model is appropriate for such retrospective study designs as well.</p>
<p>Indeed, suppose that <span class="math inline">\(y|\boldsymbol{x}\)</span> follows a logistic regression model. Let’s try to figure out the distribution of <span class="math inline">\(y|\boldsymbol{x}\)</span> in the retrospectively gathered sample. Letting <span class="math inline">\(z \in \{0,1\}\)</span> denote the indicator that an observation is sampled, define <span class="math inline">\(\rho_1 \equiv \mathbb{P}[z = 1|y = 1]\)</span> and <span class="math inline">\(\rho_0 \equiv \mathbb{P}[z = 1|y = 0]\)</span>, and assume that <span class="math inline">\(\mathbb{P}[z = 1, y, \boldsymbol{x}] = \mathbb{P}[z = 1 | y]\)</span>. The latter assumption states that the predictors <span class="math inline">\(\boldsymbol{x}\)</span> were not used in the retrospective sampling process. Then,</p>
<p><span class="math display">\[
\begin{split}
\text{logit}(\mathbb{P}[y = 1|z = 1, \boldsymbol{x}]) &amp;= \log \frac{\rho_1 \mathbb{P}[y = 1|\boldsymbol{x}]}{\rho_0 \mathbb{P}[y = 0|\boldsymbol{x}]} \\
&amp;= \log \frac{\rho_1}{\rho_0} + \text{logit}(\mathbb{P}[y = 1|\boldsymbol{x}]) \\
&amp;= \left(\log \frac{\rho_1}{\rho_0} + \beta_0\right) + \boldsymbol{x}^T \boldsymbol{\beta}_{-0}.
\end{split}
\]</span></p>
<p>Thus, conditioning on retrospective sampling changes only the intercept term, but preserves the coefficients of <span class="math inline">\(\boldsymbol{x}\)</span>. Therefore, we can carry out inference for <span class="math inline">\(\boldsymbol{\beta}_{-0}\)</span> in the same way regardless of whether the study design is prospective or retrospective.</p>
</section>
<section id="sec-estimation-inference" class="level2" data-number="24.3">
<h2 data-number="24.3" class="anchored" data-anchor-id="sec-estimation-inference"><span class="header-section-number">24.3</span> Estimation and inference</h2>
<section id="sec-score-fisher" class="level3" data-number="24.3.1">
<h3 data-number="24.3.1" class="anchored" data-anchor-id="sec-score-fisher"><span class="header-section-number">24.3.1</span> Score and Fisher information</h3>
<p>Recall from Chapter 4 that</p>
<p><span class="math display">\[
\boldsymbol{U}(\boldsymbol{\beta}) = \frac{1}{\phi_0}\boldsymbol{X}^T \boldsymbol{M} \boldsymbol{W} (\boldsymbol{y} - \boldsymbol{\mu}) \quad \text{and} \quad \boldsymbol{I}(\boldsymbol{\beta}) = \frac{1}{\phi_0}\boldsymbol{X}^T \boldsymbol{W} \boldsymbol{X},
\]</span></p>
<p>where</p>
<p><span class="math display">\[
\begin{aligned}
\boldsymbol{W} &amp;\equiv \text{diag}\left(\frac{w_i}{V(\mu_i)(d\eta_i/d\mu_i)^2}\right), \\
\boldsymbol{M} &amp;\equiv \text{diag}\left(\frac{\partial\eta_i}{\partial \mu_i}\right).
\end{aligned}
\]</span></p>
<p>Since logistic regression uses a canonical link function, we get the following simplifications:</p>
<p><span class="math display">\[
\begin{aligned}
\boldsymbol{W} &amp;= \text{diag}\left(w_i V(\mu_i)\right) = \text{diag}\left(m_i \pi_i(1-\pi_i)\right), \\
\boldsymbol{M} &amp;= \text{diag}\left(\frac{1}{\pi_i(1-\pi_i)}\right).
\end{aligned}
\]</span></p>
<p>Here we have substituted the notation <span class="math inline">\(\boldsymbol{\pi}\)</span> for <span class="math inline">\(\boldsymbol{\mu}\)</span>, and recall that for logistic regression, <span class="math inline">\(\phi_0 = 1\)</span>, <span class="math inline">\(w_i = m_i\)</span>, and <span class="math inline">\(V(\pi_i) = \pi_i(1-\pi_i)\)</span>. Therefore, the score equations for logistic regression are</p>
<p><span id="eq-logistic-score-equations"><span class="math display">\[
0 = \boldsymbol{X}^T \text{diag}\left(m_i\right)(\boldsymbol{y} - \boldsymbol{\widehat{\mu}}) \quad \Longleftrightarrow \quad \sum_{i = 1}^n m_i x_{ij}(y_i-\widehat{\pi}_i) = 0,
\tag{24.1}\]</span></span> for <span class="math inline">\(j = 0, \dots, p-1\)</span>. We can solve these equations using IRLS. The Fisher information is</p>
<p><span class="math display">\[
\boldsymbol{I}(\boldsymbol{\beta}) = \boldsymbol{X}^T \text{diag}\left(m_i \pi_i(1-\pi_i)\right) \boldsymbol{X}.
\]</span></p>
</section>
<section id="sec-wald-inference" class="level3" data-number="24.3.2">
<h3 data-number="24.3.2" class="anchored" data-anchor-id="sec-wald-inference"><span class="header-section-number">24.3.2</span> Wald inference</h3>
<p>Using the results in the previous paragraph, we can carry out Wald inference based on the normal approximation</p>
<p><span class="math display">\[
\boldsymbol{\widehat \beta} \overset \cdot \sim N\left(\boldsymbol \beta, \left(\boldsymbol X^T\text{diag}(m_i \widehat \pi_i(1-\widehat \pi_i))\boldsymbol X\right)^{-1}\right).
\]</span></p>
<p>This approximation holds for <span class="math inline">\(\sum_{i = 1}^n m_i \rightarrow \infty\)</span>.</p>
</section>
<section id="sec-2x2-contingency-table" class="level3" data-number="24.3.3">
<h3 data-number="24.3.3" class="anchored" data-anchor-id="sec-2x2-contingency-table"><span class="header-section-number">24.3.3</span> Example: <span class="math inline">\(2 \times 2\)</span> contingency table.</h3>
<p>Suppose we have a <span class="math inline">\(2 \times 2\)</span> contingency table. The grouped logistic regression formulation of these data is</p>
<p><span class="math display">\[
y_0 \sim \frac{1}{m_0}\text{Bin}(m_0, \pi_0); \quad y_1 \sim \frac{1}{m_1}\text{Bin}(m_1, \pi_1); \quad \text{logit}(\pi_i) = \beta_0 + \beta_1 x_i.
\]</span></p>
<p>In this case, we have <span class="math inline">\(n = p = 2\)</span>, so the grouped logistic regression model is saturated. Therefore, we have</p>
<p><span class="math display">\[
\hat \pi_0 = y_0, \quad \text{and} \quad \hat \pi_1 = y_1, \quad \text{so} \quad \hat \beta_1 = \log \frac{\hat \pi_1 / (1 - \hat \pi_1)}{\hat \pi_0 / (1 - \hat \pi_0)} = \log \frac{y_1 / (1 - y_1)}{y_0 / (1 - y_0)}.
\]</span></p>
<p>The squared Wald standard error for <span class="math inline">\(\hat \beta_1\)</span> is</p>
<p><span class="math display">\[
\begin{split}
\text{SE}^2(\widehat \beta_1) &amp;\equiv \left[\left(\boldsymbol X^T\text{diag}(m_i \widehat \pi_i(1-\widehat \pi_i))\boldsymbol X\right)^{-1}\right]_{22} \\
&amp;= \left[\left(\begin{pmatrix} 1 &amp; 0 \\ 1 &amp; 1 \end{pmatrix}^T\begin{pmatrix} m_0y_0(1-y_0) &amp; 0 \\ 0 &amp; m_1y_1(1-y_1) \end{pmatrix}\begin{pmatrix} 1 &amp; 0 \\ 1 &amp; 1 \end{pmatrix}\right)^{-1}\right]_{22} \\
&amp;= \left[\left(\begin{pmatrix} m_0 y_0 (1-y_0) + m_1 y_1 (1-y_1) &amp; m_1 y_1(1-y_1) \\ m_1 y_1(1-y_1) &amp; m_1 y_1(1-y_1) \end{pmatrix}\right)^{-1}\right]_{22} \\
&amp;= \frac{m_0 y_0 (1-y_0) + m_1 y_1 (1-y_1)}{m_0y_0(1-y_0) \cdot m_1y_1(1-y_1)} \\
&amp;= \frac{1}{m_0y_0(1-y_0)} + \frac{1}{m_1y_1(1-y_1)}.
\end{split}
\]</span></p>
<p>Therefore, the Wald test for <span class="math inline">\(H_0: \beta_1 = 0\)</span> rejects if</p>
<p><span class="math display">\[
\left|\frac{\hat \beta_1}{\text{SE}(\hat \beta_1)}\right| = \left|\frac{\log \frac{y_1 / (1 - y_1)}{y_0 / (1 - y_0)}}{\sqrt{\frac{1}{m_0y_0(1-y_0)} + \frac{1}{m_1y_1(1-y_1)}}}\right| &gt; z_{1-\alpha/2}.
\]</span></p>
</section>
<section id="sec-hauck-donner-effect" class="level3" data-number="24.3.4">
<h3 data-number="24.3.4" class="anchored" data-anchor-id="sec-hauck-donner-effect"><span class="header-section-number">24.3.4</span> Hauck-Donner effect.</h3>
<p>Unfortunately, Wald inference in finite samples does not always perform very well. The Wald test above is known to be conservative if one or more of the mean parameters (in this case, <span class="math inline">\(\pi_i\)</span>) tends to the edge of the parameter space (in this case, <span class="math inline">\(\pi_i \rightarrow 0\)</span> or <span class="math inline">\(\pi_i \rightarrow 1\)</span>). This is called the <em>Hauck-Donner effect</em>. As an example, consider testing <span class="math inline">\(H_0: \beta_0 = 0\)</span> in the intercept-only model</p>
<p><span class="math display">\[
my \sim \text{Bin}(m, \pi); \quad \text{logit}(\pi) = \beta_0.
\]</span></p>
<p>The Wald test statistic is <span class="math inline">\(z \equiv \widehat \beta/\text{SE} = \text{logit}(y)\sqrt{my(1-y)}\)</span>. This test statistic actually tends to <em>decrease</em> as <span class="math inline">\(y \rightarrow 1\)</span> (see <a href="#fig-hauck-donner">Figure&nbsp;<span>24.1</span></a>), since the standard error grows faster than the estimate itself. So the test statistic becomes less significant as we go further away from the null! A similar situation arises in the <span class="math inline">\(2 \times 2\)</span> contingency table example above, where the Wald test for <span class="math inline">\(H_0: \beta_1 = 0\)</span> becomes less significant as <span class="math inline">\(y_0 \rightarrow 0\)</span> and <span class="math inline">\(y_1 \rightarrow 1\)</span>. As a limiting case of this, the Wald test is undefined if <span class="math inline">\(y_0 = 0\)</span> and <span class="math inline">\(y_1 = 1\)</span>. This situation is a special case of <em>perfect separability</em> in logistic regression: when a hyperplane in covariate space separates observations with <span class="math inline">\(y_i = 0\)</span> from those with <span class="math inline">\(y_i = 1\)</span>. Some of the maximum likelihood coefficient estimates are infinite in this case, causing the Wald test to be undefined since it uses these coefficient estimates as test statistics.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-hauck-donner" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="logistic-regression_files/figure-html/fig-hauck-donner-1.png" class="img-fluid figure-img" width="480"></p>
<figcaption class="figure-caption">Figure&nbsp;24.1: The Hauck-Donner effect: The Wald statistic for testing <span class="math inline">\(H_0: \pi = 0.5\)</span> within the model <span class="math inline">\(my \sim \text{Bin}(m, \pi)\)</span> decreases as the proportion <span class="math inline">\(y\)</span> approaches 1. Here, <span class="math inline">\(m = 25\)</span>.</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="sec-likelihood-ratio-inference" class="level3" data-number="24.3.5">
<h3 data-number="24.3.5" class="anchored" data-anchor-id="sec-likelihood-ratio-inference"><span class="header-section-number">24.3.5</span> Likelihood ratio inference</h3>
<section id="sec-bernoulli-binomial-deviance" class="level4" data-number="24.3.5.1">
<h4 data-number="24.3.5.1" class="anchored" data-anchor-id="sec-bernoulli-binomial-deviance"><span class="header-section-number">24.3.5.1</span> The Bernoulli and binomial deviance.</h4>
<p>Let’s first compute the deviance of a Bernoulli or binomial model. These deviances are the same because these two models have the same natural parameter and log-partition function. The unit deviance is</p>
<p><span class="math display">\[
t(y, \pi) = y \log \pi + (1-y)\log(1-\pi).
\]</span></p>
<p>Hence, we have</p>
<p><span class="math display">\[
t(y, y) = y \log y + (1-y) \log(1-y).
\]</span></p>
<p>Hence, the unit deviance is</p>
<p><span class="math display">\[
d(y, \mu) \equiv 2(t(y,y)-t(y,\pi)) = 2\left(y \log \frac{y}{\pi} + (1-y)\log \frac{1-y}{1-\pi}\right).
\]</span></p>
<p>The total deviance, therefore, is</p>
<p><span id="eq-logistic-deviance"><span class="math display">\[
\begin{split}
D(\boldsymbol y, \hat{\boldsymbol \pi}) &amp;\equiv \sum_{i = 1}^n w_i d(y_i, \widehat \pi_i) \\
&amp;= 2\sum_{i = 1}^n \left(m_i y_i \log \frac{y_i}{\widehat \pi_i} + m_i(1-y_i) \log\frac{1-y_i}{1-\widehat \pi_i}\right).
\end{split}
\tag{24.2}\]</span></span></p>
</section>
</section>
<section id="sec-comparing-deviances" class="level3" data-number="24.3.6">
<h3 data-number="24.3.6" class="anchored" data-anchor-id="sec-comparing-deviances"><span class="header-section-number">24.3.6</span> Comparing the deviances of grouped and ungrouped logistic regression models.</h3>
<p>Let us pause to compare the total deviances of grouped and ungrouped logistic regression models. Consider the following grouped and ungrouped models:</p>
<p><span class="math display">\[
y^{\text{grp}}_i \overset{\text{ind}} \sim \frac{1}{m_i}\text{Bin}(m_i, \pi_i) \quad \text{and} \quad y^{\text{ungrp}}_{ik} \overset{\text{ind}} \sim \text{Ber}(\pi_i), \quad k = 1, \dots, m_i,
\]</span> where <span class="math display">\[
\text{logit}(\pi_i) = \boldsymbol x_{i*}^T \boldsymbol \beta.
\]</span></p>
<p>The relationship between the grouped and ungrouped observations is that</p>
<p><span class="math display">\[
y^{\text{grp}}_i = \frac{1}{m_i}\sum_{k = 1}^{m_i} y^{\text{ungrp}}_{ik} \equiv \bar y^{\text{ungrp}}_i.
\]</span></p>
<p>Since the grouped and ungrouped logistic regression models have the same likelihoods, it follows that they have the same maximum likelihood estimates <span class="math inline">\(\widehat{\boldsymbol \beta}\)</span> and <span class="math inline">\(\widehat{\boldsymbol \pi}\)</span>. However, the total deviances of the two models are different. The total deviance of the grouped model can be derived from equation (<a href="#eq-logistic-deviance"><span>24.2</span></a>):</p>
<p><span id="eq-total-deviance-grouped"><span class="math display">\[
\begin{split}
&amp;D(\boldsymbol y^{\text{grp}}, \hat{\boldsymbol \pi}) \\
&amp;\quad= 2\sum_{i = 1}^n \left(m_i y^{\text{grp}}_i \log \frac{y^{\text{grp}}_i}{\widehat \pi_i} + m_i(1-y^{\text{grp}}_i) \log\frac{1-y^{\text{grp}}_i}{1-\widehat \pi_i}\right).
\end{split}
\tag{24.3}\]</span></span></p>
<p>On the other hand, the total deviance of the ungrouped model is</p>
<p><span id="eq-total-deviance-ungrouped"><span class="math display">\[
\begin{split}
&amp;D(\boldsymbol y^{\text{ungrp}}, \hat{\boldsymbol \pi}) \\
&amp;= 2\sum_{i = 1}^n \sum_{k = 1}^{m_i} \left(y^{\text{ungrp}}_{ik} \log \frac{y^{\text{ungrp}}_{ik}}{\widehat \pi_i} + (1-y^{\text{ungrp}}_{ik}) \log\frac{1-y^{\text{ungrp}}_{ik}}{1-\widehat \pi_i}\right) \\
&amp;= 2\sum_{i = 1}^n \sum_{k = 1}^{m_i} \left(y^{\text{ungrp}}_{ik} \log \frac{1}{\widehat \pi_i} + (1-y^{\text{ungrp}}_{ik}) \log\frac{1}{1-\widehat \pi_i}\right) \\
&amp;= 2\sum_{i = 1}^n \left(m_i y^{\text{grp}}_i \log \frac{1}{\widehat \pi_i} + m_i(1-y^{\text{grp}}_i) \log\frac{1}{1-\widehat \pi_i}\right).
\end{split}
\tag{24.4}\]</span></span></p>
<p>In the second line, we used the fact that <span class="math inline">\(y \log y \rightarrow 0\)</span> and <span class="math inline">\((1-y)\log(1-y) \rightarrow 0\)</span> as <span class="math inline">\(y \rightarrow 0\)</span> or <span class="math inline">\(y \rightarrow 1\)</span>. Comparing the grouped (<a href="#eq-total-deviance-grouped"><span>24.3</span></a>) and ungrouped (<a href="#eq-total-deviance-ungrouped"><span>24.4</span></a>) total deviances, we see that these are given by related, but different expressions. Because small dispersion asymptotics applies to the grouped model but not the ungrouped model, we have that under small-dispersion asymptotics,</p>
<p><span class="math display">\[
D(\boldsymbol y^{\text{grp}}, \hat{\boldsymbol \pi}) \overset \cdot \sim \chi^2_{n-p} \quad \text{but} \quad D(\boldsymbol y^{\text{ungrp}}, \hat{\boldsymbol \pi}) \not \sim \chi^2_{n-p}.
\]</span></p>
<section id="sec-likelihood-ratio-test" class="level4" data-number="24.3.6.1">
<h4 data-number="24.3.6.1" class="anchored" data-anchor-id="sec-likelihood-ratio-test"><span class="header-section-number">24.3.6.1</span> Likelihood ratio inference for one or more coefficients.</h4>
<p>Letting <span class="math inline">\(\boldsymbol{\widehat \pi}_0\)</span> and <span class="math inline">\(\boldsymbol{\widehat \pi}_1\)</span> be the MLEs from two nested models, we can then express the likelihood ratio statistic as</p>
<p><span class="math display">\[
D(\boldsymbol y, \boldsymbol{\widehat \pi}_0) - D(\boldsymbol y, \boldsymbol{\widehat \pi}_1) = 2\sum_{i = 1}^n \left(m_i y_i \log \frac{\widehat \pi_{i1}}{\widehat \pi_{i0}} + m_i(1-y_i) \log\frac{1-\widehat \pi_{i1}}{1-\widehat \pi_{i0}}\right).
\]</span></p>
<p>Note that this expression holds for grouped or ungrouped logistic regression models. We can then construct a likelihood ratio test in the usual way. Likelihood ratio inference can be justified by either large-sample or small-dispersion asymptotics.</p>
</section>
</section>
</section>
<section id="sec-goodness-of-fit" class="level2" data-number="24.4">
<h2 data-number="24.4" class="anchored" data-anchor-id="sec-goodness-of-fit"><span class="header-section-number">24.4</span> Goodness of fit testing</h2>
<p>In grouped logistic regression, we can also use the likelihood ratio test to test goodness of fit. To do so, we compare the total deviance of the fitted model (<a href="#eq-logistic-deviance"><span>24.2</span></a>) to a chi-squared quantile. In particular, the deviance-based goodness of fit test rejects when:</p>
<p><span id="eq-goodness-of-fit"><span class="math display">\[
\begin{split}
&amp;D(\boldsymbol{y}, \hat{\boldsymbol{\pi}}) = \\
&amp;2\sum_{i = 1}^n \left(m_i y_i \log \frac{y_i}{\widehat \pi_i} + m_i(1-y_i) \log\frac{1-y_i}{1-\widehat \pi_i}\right) &gt; \chi^2_{n-p}(1-\alpha).
\end{split}
\tag{24.5}\]</span></span></p>
<p>This test is justified by small-dispersion asymptotics based on the saddlepoint approximation, which is decent when <span class="math inline">\(\min(m_i \pi_i, (1-m_i)\pi_i) \geq 3\)</span> for each <span class="math inline">\(i\)</span>.</p>
</section>
<section id="sec-example-2x2-table" class="level2" data-number="24.5">
<h2 data-number="24.5" class="anchored" data-anchor-id="sec-example-2x2-table"><span class="header-section-number">24.5</span> Example: <span class="math inline">\(2 \times 2\)</span> table</h2>
<p>Let us revisit the example of the <span class="math inline">\(2 \times 2\)</span> table model, within which we would like to test <span class="math inline">\(H_0: \beta_1 = 0\)</span>. Note that we can view this as a goodness of fit test of the intercept-only model in a grouped logistic regression model since the alternative model is the saturated model (it has two observations and two parameters). To compute the likelihood ratio statistic, we first need to fit the intercept-only model. The score equations (<a href="#eq-logistic-score-equations"><span>24.1</span></a>) reduce to:</p>
<p><span class="math display">\[
m_0 (y_0 - \hat \pi) + m_1 (y_1 - \hat \pi) = 0 \quad \Longrightarrow \quad \hat \pi_0 = \hat \pi_1 = \hat \pi = \frac{m_0 y_0 + m_1 y_1}{m_0 + m_1}.
\]</span></p>
<p>Therefore, the deviance-based test of <span class="math inline">\(H_0: \beta_1 = 0\)</span> rejects when:</p>
<p><span class="math display">\[
\begin{split}
D(\boldsymbol{y}, \boldsymbol{\widehat \pi}) &amp;= 2\sum_{i = 1}^n \left(m_i y_i \log \frac{y_i}{\widehat \pi_i} + m_i(1-y_i) \log\frac{1-y_i}{1-\widehat \pi_i}\right) \\
&amp;= \left(m_0 y_0 \log\frac{y_0}{\hat \pi} + m_0(1-y_0)\log\frac{1-y_0}{1-\hat \pi}\right) + \\
&amp;\quad \quad \left(m_1 y_1 \log\frac{y_1}{\hat \pi} + m_1(1-y_1)\log\frac{1-y_1}{1-\hat \pi}\right) \\
&amp;&gt; \chi^2_{1}(1-\alpha).
\end{split}
\]</span></p>
<p>Likelihood ratio inference can give nontrivial conclusions in cases when Wald inference cannot, e.g.&nbsp;in the case of perfect separability. In the above example, suppose <span class="math inline">\(y_0 = 0\)</span> and <span class="math inline">\(y_1 = 1\)</span>, giving perfect separability. Then, we can use the fact that <span class="math inline">\(y \log y \rightarrow 0\)</span> and <span class="math inline">\((1-y)\log(1-y) \rightarrow 0\)</span> as <span class="math inline">\(y \rightarrow 0\)</span> or <span class="math inline">\(y \rightarrow 1\)</span> to see that:</p>
<p><span id="eq-perfect-separability"><span class="math display">\[
\begin{split}
D(\boldsymbol{y}, \boldsymbol{\widehat \pi}) &amp;= 2\left(m_0 \log\frac{1}{1-\hat \pi} + m_1 \log\frac{1}{\hat \pi}\right) \\
&amp;= 2\left(m_0 \log \frac{m_0 + m_1}{m_0} + m_1 \log \frac{m_0 + m_1}{m_1}\right).
\end{split}
\tag{24.6}\]</span></span></p>
<p>This gives us a finite value, which we can compare to <span class="math inline">\(\chi^2_{1}(1-\alpha)\)</span> to test <span class="math inline">\(H_0: \beta_1 = 0\)</span>. Even though the likelihood ratio statistic is still defined, we do still have to be careful because the data may suggest that the parameters are too close to the boundary of the parameter space. However, the rate at which the test breaks down as the parameters approach this boundary is slower than the rate at which the Wald test breaks down.</p>
</section>
<section id="sec-score-based-inference" class="level2" data-number="24.6">
<h2 data-number="24.6" class="anchored" data-anchor-id="sec-score-based-inference"><span class="header-section-number">24.6</span> Score-based inference</h2>
<p>Here we present only the score-based goodness-of-fit test. Recalling <a href="glm-inference.html#sec-score-goodness-of-fit"><span>Section&nbsp;22.4.4</span></a>, the score statistic for goodness of fit is Pearson’s <span class="math inline">\(X^2\)</span> statistic:</p>
<p><span id="eq-pearson-statistic"><span class="math display">\[
X^2 = \sum_{i = 1}^n \frac{w_i (y_i - \widehat \mu_i)^2}{V(\widehat \mu_i)} = \sum_{i = 1}^n \frac{m_i(y_i - \widehat \pi_i)^2}{\widehat \pi_i(1-\widehat \pi_i)}.
\tag{24.7}\]</span></span></p>
<p>This test is justified by small-dispersion asymptotics based on the central limit theorem, which is decent when <span class="math inline">\(\min(m_i \pi_i, (1-m_i)\pi_i) \geq 5\)</span> for each <span class="math inline">\(i\)</span>.</p>
</section>
<section id="sec-fisher-exact-test" class="level2" data-number="24.7">
<h2 data-number="24.7" class="anchored" data-anchor-id="sec-fisher-exact-test"><span class="header-section-number">24.7</span> Fisher’s exact test</h2>
<p>As an alternative to asymptotic tests for logistic regression, in the case of <span class="math inline">\(2 \times 2\)</span> tables, there is an <em>exact</em> test of <span class="math inline">\(H_0: \beta_1 = 0\)</span>. Suppose we have:</p>
<p><span id="eq-binomial"><span class="math display">\[
s_1 = m_1y_1 \sim \text{Bin}(m_1, \pi_1) \quad \text{and} \quad s_2 = m_2y_2 \sim \text{Bin}(m_2, \pi_2).
\tag{24.8}\]</span></span></p>
<p>The trick is to conduct inference <em>conditional on</em> <span class="math inline">\(s_1 + s_2\)</span>. Note that under <span class="math inline">\(H_0: \pi_1 = \pi_2\)</span>, we have:</p>
<p><span id="eq-exact-test"><span class="math display">\[
\begin{split}
&amp;\mathbb{P}[s_1 = t | s_1+s_2 = v] \\
&amp;\quad= \mathbb{P}[s_1 = t | s_1 + s_2 = v] \\
&amp;\quad= \frac{\mathbb{P}[s_1 = t, s_2 = v-t]}{\mathbb{P}[s_1 + s_2 = v]} \\
&amp;\quad= \frac{{m_1 \choose t}\pi^{t}(1-\pi)^{m_1 - t}{m_2 \choose v-t}\pi^{v-t}(1-\pi)^{m_2 - (v-t)}}{{m_1 + m_2 \choose v}\pi^v (1-\pi)^{m_1 + m_2 - v}} \\
&amp;\quad= \frac{{m_1 \choose t}{m_2 \choose v-t}}{{m_1 + m_2 \choose v}}.
\end{split}
\tag{24.9}\]</span></span></p>
<p>Therefore, a finite-sample <span class="math inline">\(p\)</span>-value to test <span class="math inline">\(H_0: \pi_1 = \pi_2\)</span> versus <span class="math inline">\(H_1: \pi_1 &gt; \pi_2\)</span> is <span class="math inline">\(\mathbb{P}[s_1 \geq t | s_1 + s_2]\)</span>, which can be computed exactly based on the formula above.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./glm-special-cases.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Generalized linear models: Special cases</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./poisson-regression.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Poisson regression</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>